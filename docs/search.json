[{"path":"/articles/errors.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"","text":"Package sastats includes convenience functions estimating survey sampling errors. simple calculations, functions just thin wrappers bit code. Relevant measures: Standard error mean: error_se_mean() Standard error proportion: error_se_prop() Margin error (confidence intervals): error_me()","code":""},{"path":"/articles/errors.html","id":"notes","dir":"Articles","previous_headings":"Overview","what":"Notes","title":"","text":"Package survey provides much comprehensive approach survey-based calculations (errors, weighting, etc.). ’ve tended toward light-weight approach outlined , worth looking alot survey analysis R. Caculating errors multi-estimate metrics requires error propagation (e.g., total days depends participation rate & average days) . haven’t implemented computations , existing packages address need. Package propagate one ’ve used, found tricky implement. Package errors newer appears straightforward (although haven’t tested ).","code":""},{"path":"/articles/errors.html","id":"example-data","dir":"Articles","previous_headings":"Overview","what":"Example Data","title":"","text":"demonstration, package sastats includes survey dataset annual participation metrics 9 outdoor recreation activities:","code":"library(dplyr) library(sastats) data(svy)  activity <- left_join(svy$act, select(svy$person, Vrid, weight), by = \"Vrid\") glimpse(activity) #> Rows: 11,268 #> Columns: 5 #> $ Vrid   <chr> \"98\", \"99\", \"100\", \"101\", \"102\", \"103\", \"105\", \"106\", \"107\", \"1… #> $ act    <chr> \"trail\", \"trail\", \"trail\", \"trail\", \"trail\", \"trail\", \"trail\", … #> $ part   <chr> \"Unchecked\", \"Unchecked\", \"Unchecked\", \"Unchecked\", \"Unchecked\"… #> $ days   <dbl> NA, NA, NA, NA, NA, NA, NA, NA, 15, 10, NA, 2, NA, NA, 10, NA, … #> $ weight <dbl> 0.9596845, 1.0899973, 1.0000000, 0.8747500, 0.9641894, 0.924523…"},{"path":"/articles/errors.html","id":"se-mean","dir":"Articles","previous_headings":"Overview","what":"SE Mean","title":"","text":"Looking days participation:","code":"days <- activity %>%     group_by(act) %>%      summarise(         avgdays = weighted.mean(days, weight, na.rm = TRUE),         se = error_se_mean(days, na.rm = TRUE) ) days #> # A tibble: 9 × 3 #>   act      avgdays    se #>   <chr>      <dbl> <dbl> #> 1 bike       30.4  2.97  #> 2 camp       10.9  1.28  #> 3 fish       10.6  1.49  #> 4 hunt        8.93 1.41  #> 5 picnic     18.6  1.35  #> 6 snow        9.60 0.856 #> 7 trail      26.9  2.58  #> 8 water      11.8  1.24  #> 9 wildlife   26.9  2.96"},{"path":"/articles/errors.html","id":"se-proportion","dir":"Articles","previous_headings":"Overview","what":"SE Proportion","title":"","text":"Looking participation rate:","code":"rate <- activity %>%     group_by(act, part) %>%     summarise(n = n(), wtn = sum(weight)) %>%     mutate(         n = sum(n),          rate = wtn / sum(wtn),         se = error_se_prop(rate, n)     ) %>%     filter(part == \"Checked\") #> `summarise()` has grouped output by 'act'. You can override using the `.groups` #> argument. rate #> # A tibble: 9 × 6 #> # Groups:   act [9] #>   act      part        n   wtn  rate      se #>   <chr>    <chr>   <int> <dbl> <dbl>   <dbl> #> 1 bike     Checked  1252  381. 0.304 0.0130  #> 2 camp     Checked  1252  469. 0.375 0.0137  #> 3 fish     Checked  1252  323. 0.258 0.0124  #> 4 hunt     Checked  1252  173. 0.138 0.00976 #> 5 picnic   Checked  1252  870. 0.695 0.0130  #> 6 snow     Checked  1252  309. 0.247 0.0122  #> 7 trail    Checked  1252  452. 0.361 0.0136  #> 8 water    Checked  1252  377. 0.301 0.0130  #> 9 wildlife Checked  1252  484. 0.386 0.0138"},{"path":"/articles/errors.html","id":"margin-of-error","dir":"Articles","previous_headings":"Overview","what":"Margin of Error","title":"","text":"useful reporting confidence intervals. Note dataset weighting produces “design effect” inflates margin error. know design effect dataset, based summary output produced sastats::rake_weight() procedure.","code":"deff <- 1.19 rate <- mutate(rate, me = error_me(se) * deff, lower = rate - me, upper = rate + me) days <- mutate(days, me = error_me(se) * deff, lower = avgdays - me, upper = avgdays + me)  library(ggplot2) ggplot(rate, aes(act, rate)) +   geom_point() +   geom_errorbar(aes(ymin = lower, ymax = upper)) +   ggtitle(\"Participation Rate Estimates (with 95% CIs)\") ggplot(days, aes(act, avgdays)) +   geom_point() +   geom_errorbar(aes(ymin = lower, ymax = upper)) +   ggtitle(\"Average Days (per participant) Estimates (with 95% CIs)\")"},{"path":"/articles/outliers.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"","text":"Outliers considered working continuous survey variables. hard fast rules outlier identification, Tukey’s Test provides one method easy apply standard way. can view production example B4W-19-01. Package sastats includes simple outlier functions: visualizing: outlier_plot() identification: outlier_tukey() top-coding: outlier_tukey_top()","code":""},{"path":"/articles/outliers.html","id":"example-data","dir":"Articles","previous_headings":"Overview","what":"Example Data","title":"","text":"demonstration, included survey dataset annual participation metrics 9 outdoor recreation activities:","code":"library(dplyr) library(sastats)  data(svy) # list with 2 data frames: person, act activities <- svy$act  glimpse(activities) #> Rows: 11,268 #> Columns: 4 #> $ Vrid <chr> \"98\", \"99\", \"100\", \"101\", \"102\", \"103\", \"105\", \"106\", \"107\", \"108… #> $ act  <chr> \"trail\", \"trail\", \"trail\", \"trail\", \"trail\", \"trail\", \"trail\", \"t… #> $ part <chr> \"Unchecked\", \"Unchecked\", \"Unchecked\", \"Unchecked\", \"Unchecked\", … #> $ days <dbl> NA, NA, NA, NA, NA, NA, NA, NA, 15, 10, NA, 2, NA, NA, 10, NA, NA…"},{"path":"/articles/outliers.html","id":"visualize","dir":"Articles","previous_headings":"Overview","what":"Visualize","title":"","text":"Visualizing data good first step. can use outlier_plot() largely wrapper ggplot2 functions. ignore_zero = TRUE specification ensures exclude respondents didn’t actually participate.  running function, can see distributions highly skewed difficult view. Additionally, position whiskers suggests flagging many reasonable values outliers (e.g., 20 fishing). Log-transforming y-axis (apply_log = TRUE) produces normal distributions, likely provides reasonable criteria outlier identification. Note don’t need supply ignore_zero = TRUE since log(0) undefined.","code":"outlier_plot(activities, days, act, ignore_zero = TRUE) outlier_plot(activities, days, act, apply_log = TRUE)"},{"path":"/articles/outliers.html","id":"flag-outliers","dir":"Articles","previous_headings":"Overview","what":"Flag Outliers","title":"","text":"can use outlier_tukey() flag values observed outliers:  also couple summary functions available demonstrate effects outlier removal:","code":"activities <- activities %>%     group_by(act) %>%      mutate(         is_outlier = outlier_tukey(days, apply_log = TRUE),          days_cleaned = ifelse(is_outlier, NA, days)      ) %>%      ungroup()  outlier_plot(activities, days, act, apply_log = TRUE, show_outliers = TRUE) outlier_pct(activities, act) #> # A tibble: 8 × 4 #> # Groups:   act [8] #>   act      is_outlier     n pct_outliers #>   <chr>    <lgl>      <int>        <dbl> #> 1 camp     TRUE           6       0.479  #> 2 fish     TRUE           3       0.240  #> 3 hunt     TRUE           1       0.0799 #> 4 picnic   TRUE          15       1.20   #> 5 snow     TRUE           2       0.160  #> 6 trail    TRUE           4       0.319  #> 7 water    TRUE           4       0.319  #> 8 wildlife TRUE          13       1.04  outlier_mean_compare(activities, days, days_cleaned, act)  #> # A tibble: 9 × 3 #>   act       days days_cleaned #>   <chr>    <dbl>        <dbl> #> 1 bike     31.6         31.6  #> 2 camp     11.2          8.58 #> 3 fish     11.6          9.40 #> 4 hunt      9.37         8.34 #> 5 picnic   17.5         13.1  #> 6 snow      9.99         9.29 #> 7 trail    28.4         25.5  #> 8 water    12.4         10.5  #> 9 wildlife 30.5         21.8"},{"path":"/articles/outliers.html","id":"topcode","dir":"Articles","previous_headings":"Overview > Flag Outliers","what":"Topcode","title":"","text":"Instead removing outliers, use outlier_tukey_top() identify topcode value recode accordingly:","code":"activities <- activities %>%     group_by(act) %>%     mutate(         topcode_value = outlier_tukey_top(days, apply_log = TRUE),         days_cleaned = ifelse(is_outlier, topcode_value, days)     ) %>%     ungroup()  outlier_mean_compare(activities, days, days_cleaned, act) #> # A tibble: 9 × 3 #>   act       days days_cleaned #>   <chr>    <dbl>        <dbl> #> 1 bike     31.6         31.6  #> 2 camp     11.2          9.30 #> 3 fish     11.6         10.5  #> 4 hunt      9.37         9.05 #> 5 picnic   17.5         15.8  #> 6 snow      9.99         9.91 #> 7 trail    28.4         28.1  #> 8 water    12.4         11.5  #> 9 wildlife 30.5         28.6"},{"path":"/articles/weight.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"","text":"Rake weighting R fairly straightforward using anesrake::anesrake(), sastats::rake_weight() thin wrapper. key aspect process getting two input datasets right format: target population dataset needs named list (one element per demographic variable) target distributions. weights::wpct() function helps . survey dataset needs data frame unique ID variable (e.g., Vrid), one variable demographic measure. Importantly, demographic variables must stored either factors numerics category coding much match two datasets. can also see production examples B4W-19-10 /HS: rakewt-ashs.","code":""},{"path":"/articles/weight.html","id":"example-data","dir":"Articles","previous_headings":"Overview","what":"Example Data","title":"","text":"demonstration, package sastats includes survey population datasets include several demographic variables: Importantly, demographic variables encoded way 2 datasets (factors case):","code":"library(dplyr) library(sastats)  data(svy, pop) svy <- select(svy$person, -weight)  # survey to be weighted glimpse(svy) #> Rows: 1,252 #> Columns: 5 #> $ Vrid          <chr> \"98\", \"99\", \"100\", \"101\", \"102\", \"103\", \"105\", \"106\", \"1… #> $ sex           <fct> Female, Female, NA, Male, Female, Male, Male, Female, Ma… #> $ age_weight    <fct> 35-54, 35-54, NA, 35-54, 35-54, 18-34, 18-34, 35-54, 35-… #> $ income_weight <fct> 0-25K, 0-25K, NA, 25-35K, 50-75K, 25-35K, 50-75K, 35-50K… #> $ race_weight   <fct> White, Not white or Hispanic, NA, White, Not white or Hi…  # target population (outdoor recreationists) from a genpop survey glimpse(pop) #> Rows: 877 #> Columns: 5 #> $ sex           <fct> Female, Female, Female, Male, Female, Female, Female, Fe… #> $ age_weight    <fct> 18-34, 18-34, 18-34, 18-34, 18-34, 35-54, 35-54, 35-54, … #> $ income_weight <fct> 75-100K, 35-50K, 0-25K, 150K+, 0-25K, 25-35K, 75-100K, N… #> $ race_weight   <fct> White, White, Hispanic, White, White, White, White, Whit… #> $ stwt          <dbl> 0.8927761, 0.8927761, 1.1913576, 1.1056643, 0.8073446, 0… wtvars <- setdiff(names(svy), \"Vrid\") sapply(wtvars, function(x) all(levels(svy[[x]]) == levels(pop[[x]]))) #>           sex    age_weight income_weight   race_weight  #>          TRUE          TRUE          TRUE          TRUE"},{"path":"/articles/weight.html","id":"population-distributions","dir":"Articles","previous_headings":"Overview","what":"Population Distributions","title":"","text":"easiest way see format needed target population run weights::wpct() demographic variable: example, defining target population (outdoor recreationists) using another general population survey dataset. case, need ensure use stwt variable survey since weighted: weights::wpct() function returns vector, need list vectors (one element per demographic variables interest). straightforward method involves looping demographic variables sapply(): weren’t using reference population dataset, need get target distributions list way. example, hand: Using weights::wpct() also course provides convenient method comparison survey dataset weighted:","code":"weights::wpct(svy$age_weight) #>     18-34     35-54       55+  #> 0.2766497 0.2944162 0.4289340 weights::wpct(pop$age_weight, pop$stwt) #>     18-34     35-54       55+  #> 0.3514503 0.3486601 0.2998896 pop_target <- sapply(wtvars, function(x) weights::wpct(pop[[x]], pop[[\"stwt\"]])) pop_target #> $sex #>    Male  Female  #> 0.51747 0.48253  #>  #> $age_weight #>     18-34     35-54       55+  #> 0.3514503 0.3486601 0.2998896  #>  #> $income_weight #>      0-25K     25-35K     35-50K     50-75K    75-100K   100-150K      150K+  #> 0.17353726 0.09405487 0.14064324 0.18922885 0.15252025 0.16103245 0.08898309  #>  #> $race_weight #>                 White              Hispanic Not white or Hispanic  #>            0.73559778            0.17719770            0.08720452 partial_target <- list(     \"sex\" = c(\"Male\" = 0.517, \"Female\" = 0.483),     \"age_weight\" = c(\"18-34\" = 0.351, \"35-54\" = 0.349, \"55+\" = 0.300)     # etc. ) partial_target #> $sex #>   Male Female  #>  0.517  0.483  #>  #> $age_weight #> 18-34 35-54   55+  #> 0.351 0.349 0.300 sapply(wtvars, function(x) weights::wpct(svy[[x]])) #> $sex #>      Male    Female  #> 0.4318374 0.5681626  #>  #> $age_weight #>     18-34     35-54       55+  #> 0.2766497 0.2944162 0.4289340  #>  #> $income_weight #>      0-25K     25-35K     35-50K     50-75K    75-100K   100-150K      150K+  #> 0.15071973 0.12785775 0.14309907 0.20491109 0.15071973 0.15410669 0.06858594  #>  #> $race_weight #>                 White              Hispanic Not white or Hispanic  #>            0.82387807            0.09652837            0.07959356"},{"path":"/articles/weight.html","id":"rake-weighting","dir":"Articles","previous_headings":"Overview","what":"Rake Weighting","title":"","text":"can now run rake weighting procedure. default, rake_weight() returns list 2 elements: (1) survey dataset weight variable appended, (2) anesrake() return object, includes bunch useful summary statistics (including “design effect”, may useful estimating confidence intervals).","code":"svy_wts <- rake_weight(svy, pop_target, \"Vrid\") #> Warning in anesrake::anesrake(pop, svy, caseid = svy[[idvar]], ...): Targets for #> age_weight do not sum to 100%. Adjusting values to total 100% #> [1] \"Raking converged in 22 iterations\"  svy <- svy_wts$svy summary(svy$weight) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  0.3568  0.7408  0.9245  1.0000  1.1662  2.6893  wt_summary <- summary(svy_wts$wts) deff <- wt_summary$general.design.effect deff #> [1] 1.186242  wt_summary #> $convergence #> [1] \"Complete convergence was achieved after 22 iterations\" #>  #> $base.weights #> [1] \"No Base Weights Were Used\" #>  #> $raking.variables #> [1] \"sex\"           \"age_weight\"    \"income_weight\" \"race_weight\"   #>  #> $weight.summary #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  0.3568  0.7408  0.9245  1.0000  1.1662  2.6893  #>  #> $selection.method #> [1] \"variable selection conducted using _pctlim_ - discrepancies selected using _total_.\" #>  #> $general.design.effect #> [1] 1.186242 #>  #> $sex #>         Target Unweighted N Unweighted %     Wtd N   Wtd % Change in % #> Male   0.51747          510    0.4318374  611.2812 0.51747  0.08563258 #> Female 0.48253          671    0.5681626  570.0070 0.48253 -0.08563258 #> Total  1.00000         1181    1.0000000 1181.2882 1.00000  0.17126517 #>         Resid. Disc. Orig. Disc. #> Male   -3.330669e-16  0.08563258 #> Female  1.665335e-16 -0.08563258 #> Total   4.996004e-16  0.17126517 #>  #> $age_weight #>          Target Unweighted N Unweighted %     Wtd N     Wtd % Change in % #> 18-34 0.3514503          327    0.2766497  415.4143 0.3514503  0.07480056 #> 35-54 0.3486601          348    0.2944162  412.1162 0.3486601  0.05424384 #> 55+   0.2998896          507    0.4289340  354.4695 0.2998896 -0.12904440 #> Total 1.0000000         1182    1.0000000 1182.0000 1.0000000  0.25808881 #>        Resid. Disc. Orig. Disc. #> 18-34 -5.551115e-17  0.07480056 #> 35-54  0.000000e+00  0.05424384 #> 55+    5.551115e-17 -0.12904440 #> Total  1.110223e-16  0.25808881 #>  #> $income_weight #>              Target Unweighted N Unweighted %     Wtd N      Wtd %  Change in % #> 0-25K    0.17353726          178   0.15071973  204.9975 0.17353726  0.022817533 #> 25-35K   0.09405487          151   0.12785775  111.1059 0.09405487 -0.033802878 #> 35-50K   0.14064324          169   0.14309907  166.1402 0.14064324 -0.002455831 #> 50-75K   0.18922885          242   0.20491109  223.5338 0.18922885 -0.015682244 #> 75-100K  0.15252025          178   0.15071973  180.1704 0.15252025  0.001800522 #> 100-150K 0.16103245          182   0.15410669  190.2257 0.16103245  0.006925756 #> 150K+    0.08898309           81   0.06858594  105.1147 0.08898309  0.020397142 #> Total    1.00000000         1181   1.00000000 1181.2882 1.00000000  0.103881906 #>           Resid. Disc.  Orig. Disc. #> 0-25K     1.110223e-16  0.022817533 #> 25-35K    2.775558e-17 -0.033802878 #> 35-50K    5.551115e-17 -0.002455831 #> 50-75K    5.551115e-17 -0.015682244 #> 75-100K   2.775558e-17  0.001800522 #> 100-150K -8.326673e-17  0.006925756 #> 150K+     2.775558e-17  0.020397142 #> Total     3.885781e-16  0.103881906 #>  #> $race_weight #>                           Target Unweighted N Unweighted %     Wtd N      Wtd % #> White                 0.73559778          973   0.82387807  868.9530 0.73559778 #> Hispanic              0.17719770          114   0.09652837  209.3216 0.17719770 #> Not white or Hispanic 0.08720452           94   0.07959356  103.0137 0.08720452 #> Total                 1.00000000         1181   1.00000000 1181.2882 1.00000000 #>                        Change in %  Resid. Disc.  Orig. Disc. #> White                 -0.088280289 -1.110223e-16 -0.088280289 #> Hispanic               0.080669338  5.551115e-17  0.080669338 #> Not white or Hispanic  0.007610952 -1.387779e-17  0.007610952 #> Total                  0.176560579  1.804112e-16  0.176560579"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Dan Kary. Maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Kary D (2022). sastats: Calculate Statistics. R package version 1.0, https://github.com/southwick-associates/sastats.","code":"@Manual{,   title = {sastats: Calculate Statistics},   author = {Dan Kary},   year = {2022},   note = {R package version 1.0},   url = {https://github.com/southwick-associates/sastats}, }"},{"path":"/index.html","id":"sastats","dir":"","previous_headings":"","what":"Calculate Statistics","title":"Calculate Statistics","text":"Southwick package useful statistics calculations (particularly regard surveys)","code":""},{"path":"/index.html","id":"description","dir":"","previous_headings":"","what":"Description:","title":"Calculate Statistics","text":"package provides several useful statistics calculations including identifying outliers, calculating survey sampling error survey rake weighting.","code":""},{"path":"/index.html","id":"exported-functions","dir":"","previous_headings":"","what":"Exported Functions:","title":"Calculate Statistics","text":"error_me, error_se_mean, error_se_prop, outlier_mean_compare, outlier_pct, outlier_plot, outlier_tukey, outlier_tukey_top, rake_weight","code":""},{"path":"/index.html","id":"example","dir":"","previous_headings":"","what":"Example:","title":"Calculate Statistics","text":"","code":"library(dplyr) data(svy) outlier_plot(svy$act, days, act) outlier_plot(svy$act, days, act,apply_log = TRUE)"},{"path":"/index.html","id":"github-and-website-information","dir":"","previous_headings":"","what":"Github and website information","title":"Calculate Statistics","text":"Github link: https://github.com/southwick-associates/sastats deployed website: https://jhu-statprogramming-fall-2022.github.io/biostat840-project3-pkgdown-yixuan-chen-elisa pkgdown website: modify entire appearance website change fonts used majority text,headings code change color syntax highlighting code box customize navigation bar customize side bar","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Calculate Statistics","text":"R console:","code":"install.packages(\"remotes\") remotes::install_github(\"southwick-associates/sastats\")"},{"path":"/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Calculate Statistics","text":"See vignettes: Identifying Outliers Survey Sampling Errors Survey Rake Weighting Note package doesn’t implement error propagation. errors package looks promising regard, although haven’t tried yet.","code":""},{"path":"/index.html","id":"development","dir":"","previous_headings":"","what":"Development","title":"Calculate Statistics","text":"See R packages book guide package development. software environment specified using package renv. Use renv::restore() build project library.","code":""},{"path":"/reference/error_me.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Margin of Error at given confidence level — error_me","title":"Calculate Margin of Error at given confidence level — error_me","text":"particularly useful constructing confidence intervals.","code":""},{"path":"/reference/error_me.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Margin of Error at given confidence level — error_me","text":"","code":"error_me(std_error, confidence = 0.95)"},{"path":"/reference/error_me.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Margin of Error at given confidence level — error_me","text":"std_error numeric: Estimated standard error confidence numeric: Confidence level (0 < confidence < 1). default approximately equal std_error * 1.96","code":""},{"path":"/reference/error_me.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate Margin of Error at given confidence level — error_me","text":"http://en.wikipedia.org/wiki/Margin_of_error","code":""},{"path":[]},{"path":"/reference/error_me.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Margin of Error at given confidence level — error_me","text":"","code":"# maximum margin of error (proportion) for N=100: 9.8% std_error <- error_se_prop(0.5, 100) error_me(std_error) #> [1] 0.0979982  # margin of error for mean x <- rlnorm(50, 3) summary(x) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>   1.454  10.453  18.771  30.796  37.508 166.106  std_error <- error_se_mean(x) error_me(std_error) #> [1] 9.254802"},{"path":"/reference/error_se_mean.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Standard Error of the Mean — error_se_mean","title":"Calculate Standard Error of the Mean — error_se_mean","text":"Calculate Standard Error Mean","code":""},{"path":"/reference/error_se_mean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Standard Error of the Mean — error_se_mean","text":"","code":"error_se_mean(x, na.rm = FALSE)"},{"path":"/reference/error_se_mean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Standard Error of the Mean — error_se_mean","text":"x vector: Input numeric vector summarized na.rm logical: TRUE, NA (missing) values ignored.","code":""},{"path":"/reference/error_se_mean.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate Standard Error of the Mean — error_se_mean","text":"http://en.wikipedia.org/wiki/Standard_error","code":""},{"path":[]},{"path":"/reference/error_se_mean.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Standard Error of the Mean — error_se_mean","text":"","code":"# generate some measurements & estimate std. error x <- rlnorm(50, 3) summary(x) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>   1.967  10.522  27.491  39.290  41.590 274.478  error_se_mean(x) #> [1] 6.375969  # introduce some missing values nas <- rbinom(50, 1, 0.1) x <- ifelse(nas, NA_integer_, x) summary(x) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's  #>   1.967   9.436  28.102  38.794  41.499 274.478       7  error_se_mean(x) # doesn't work #> [1] NA error_se_mean(x, na.rm = TRUE) #> [1] 7.179158"},{"path":"/reference/error_se_prop.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Standard Error of a Proportion — error_se_prop","title":"Calculate Standard Error of a Proportion — error_se_prop","text":"Calculate Standard Error Proportion","code":""},{"path":"/reference/error_se_prop.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Standard Error of a Proportion — error_se_prop","text":"","code":"error_se_prop(pct, N)"},{"path":"/reference/error_se_prop.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Standard Error of a Proportion — error_se_prop","text":"pct numeric: Estimated proportion N numeric: Number Responses","code":""},{"path":"/reference/error_se_prop.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate Standard Error of a Proportion — error_se_prop","text":"http://en.wikipedia.org/wiki/Standard_error","code":""},{"path":[]},{"path":"/reference/error_se_prop.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Standard Error of a Proportion — error_se_prop","text":"","code":"# standard error for N=30, pct=33%/67% x <- c(rep(\"Checked\", 10), rep(\"Unchecked\", 20)) N <- length(x) pct <- prop.table(table(x)) error_se_prop(pct, N) #> x #>   Checked Unchecked  #> 0.0860663 0.0860663"},{"path":"/reference/outlier_mean_compare.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare averages with (newvar) vs. withoout (oldvar) outliers — outlier_mean_compare","title":"Compare averages with (newvar) vs. withoout (oldvar) outliers — outlier_mean_compare","text":"Compare averages (newvar) vs. withoout (oldvar) outliers","code":""},{"path":"/reference/outlier_mean_compare.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare averages with (newvar) vs. withoout (oldvar) outliers — outlier_mean_compare","text":"","code":"outlier_mean_compare(df, oldvar, newvar, ...)"},{"path":"/reference/outlier_mean_compare.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare averages with (newvar) vs. withoout (oldvar) outliers — outlier_mean_compare","text":"df data frame variables compare oldvar original variable without outliers removed newvar variable outliers removed ... optional grouping variables (use unquoted names)","code":""},{"path":[]},{"path":"/reference/outlier_mean_compare.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compare averages with (newvar) vs. withoout (oldvar) outliers — outlier_mean_compare","text":"","code":"# see ?outlier_tukey"},{"path":"/reference/outlier_pct.html","id":null,"dir":"Reference","previous_headings":"","what":"Identify the percentage of values flagged as outliers — outlier_pct","title":"Identify the percentage of values flagged as outliers — outlier_pct","text":"Identify percentage values flagged outliers","code":""},{"path":"/reference/outlier_pct.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identify the percentage of values flagged as outliers — outlier_pct","text":"","code":"outlier_pct(df, ...)"},{"path":"/reference/outlier_pct.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identify the percentage of values flagged as outliers — outlier_pct","text":"df data frame outliers identified df$is_outlier ... optional grouping variables (use unquoted names)","code":""},{"path":[]},{"path":"/reference/outlier_pct.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Identify the percentage of values flagged as outliers — outlier_pct","text":"","code":"# see ?outlier_tukey"},{"path":"/reference/outlier_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Make boxplots of numberic variable — outlier_plot","title":"Make boxplots of numberic variable — outlier_plot","text":"function can optionally show outliers identifying df$is_outliers show_outliers = TRUE.","code":""},{"path":"/reference/outlier_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make boxplots of numberic variable — outlier_plot","text":"","code":"outlier_plot(   df,   var,   grp,   apply_log = FALSE,   show_outliers = FALSE,   ignore_zero = FALSE )"},{"path":"/reference/outlier_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make boxplots of numberic variable — outlier_plot","text":"df data frame outliers identified df$is_outlier var Unquoted name variable check grp Unquoted name variable group apply_log TRUE, log transform input values prior applying tukey's rule. Useful since distributions often log-normal shape (e.g., spending) show_outliers TRUE, identify values flagged df$is_outlier ignore_zero TRUE, exclude zero values IQR & flagging. Note zeroes automatically ignored apply_log = TRUE","code":""},{"path":[]},{"path":"/reference/outlier_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make boxplots of numberic variable — outlier_plot","text":"","code":"# see ?outlier_tukey"},{"path":"/reference/outlier_tukey.html","id":null,"dir":"Reference","previous_headings":"","what":"Flag outliers based on tukey's rule — outlier_tukey","title":"Flag outliers based on tukey's rule — outlier_tukey","text":"Returns logical vector TRUE indicates outliers.","code":""},{"path":"/reference/outlier_tukey.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Flag outliers based on tukey's rule — outlier_tukey","text":"","code":"outlier_tukey(   x,   k = 1.5,   ignore_lwr = FALSE,   apply_log = FALSE,   ignore_zero = FALSE )  outlier_tukey_top(x, k = 1.5, apply_log = FALSE, ignore_zero = FALSE)"},{"path":"/reference/outlier_tukey.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Flag outliers based on tukey's rule — outlier_tukey","text":"x input values check k iqr multiplier determines fence level. Increasing make outlier identification less strict (& vice-versa) ignore_lwr TRUE, use lower fence identifying outliers apply_log TRUE, log transform input values prior applying tukey's rule. Useful since distributions often log-normal shape (e.g., spending) ignore_zero TRUE, exclude zero values IQR & flagging. Note zeroes automatically ignored apply_log = TRUE","code":""},{"path":"/reference/outlier_tukey.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Flag outliers based on tukey's rule — outlier_tukey","text":"outlier_tukey_top: get largest non-outlier value top-coding","code":""},{"path":[]},{"path":"/reference/outlier_tukey.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Flag outliers based on tukey's rule — outlier_tukey","text":"","code":"library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union data(svy)  # take a look at the days variable outlier_plot(svy$act, days, act)  outlier_plot(svy$act, days, act, apply_log = TRUE)   activity <- group_by(svy$act, act) %>% mutate(     is_outlier = outlier_tukey(days, ignore_zero = TRUE, apply_log = TRUE),     # in case we want to topcode the outliers:     topcode_value = outlier_tukey_top(days, apply_log = TRUE),     days_cleaned = ifelse(is_outlier, NA, days) ) %>% ungroup()  # summarize outlier_plot(activity, days, act, apply_log = TRUE, show_outliers = TRUE)  outlier_pct(activity, act) #> # A tibble: 8 × 4 #> # Groups:   act [8] #>   act      is_outlier     n pct_outliers #>   <chr>    <lgl>      <int>        <dbl> #> 1 camp     TRUE           6       0.479  #> 2 fish     TRUE           3       0.240  #> 3 hunt     TRUE           1       0.0799 #> 4 picnic   TRUE          15       1.20   #> 5 snow     TRUE           2       0.160  #> 6 trail    TRUE           4       0.319  #> 7 water    TRUE           4       0.319  #> 8 wildlife TRUE          13       1.04   outlier_mean_compare(activity, days, days_cleaned, act) #> # A tibble: 9 × 3 #>   act       days days_cleaned #>   <chr>    <dbl>        <dbl> #> 1 bike     31.6         31.6  #> 2 camp     11.2          8.58 #> 3 fish     11.6          9.40 #> 4 hunt      9.37         8.34 #> 5 picnic   17.5         13.1  #> 6 snow      9.99         9.29 #> 7 trail    28.4         25.5  #> 8 water    12.4         10.5  #> 9 wildlife 30.5         21.8"},{"path":"/reference/pop.html","id":null,"dir":"Reference","previous_headings":"","what":"Survey data for defining a population — pop","title":"Survey data for defining a population — pop","text":"Survey data defining population","code":""},{"path":"/reference/pop.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Survey data for defining a population — pop","text":"","code":"pop"},{"path":"/reference/pop.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Survey data for defining a population — pop","text":"data frame 877 rows 4 columns (1 row per respondent)","code":""},{"path":[]},{"path":"/reference/rake_weight.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate rake weights for input survey data & population distributions — rake_weight","title":"Estimate rake weights for input survey data & population distributions — rake_weight","text":"thin wrapper anesrake. return_stats = TRUE, returns list (1) survey dataset (2) anesrake() object. Otherwise, prints summary returns just survey dataset weight variable appended.","code":""},{"path":"/reference/rake_weight.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate rake weights for input survey data & population distributions — rake_weight","text":"","code":"rake_weight(   svy,   pop,   idvar,   weightvar = \"weight\",   return_stats = TRUE,   print_name = \"\",   ... )"},{"path":"/reference/rake_weight.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate rake weights for input survey data & population distributions — rake_weight","text":"svy survey data frame pop list holds population distributions weighting variables. idvar name varible holds unique id weightvar name output weight variable return_stats TRUE, function instead return list 2 elements: (1) survey data frame new weight variable, (2) object returned directly anesrake(). helpful want later pull elements design effect confidence interval calculations. print_name header print summary (useful log output) ... arguments passed anesrake()","code":""},{"path":"/reference/rake_weight.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate rake weights for input survey data & population distributions — rake_weight","text":"","code":"data(svy, pop) svy <- svy$person  # determine target weight values # the population is determined by a survey dataset which is itself weighted wtvars <- c(\"age_weight\", \"income_weight\", \"race_weight\") pop_target <- sapply(wtvars, function(x) weights::wpct(pop[[x]], pop$stwt))  # compare distributions for survey and population pop_target #> $age_weight #>     18-34     35-54       55+  #> 0.3514503 0.3486601 0.2998896  #>  #> $income_weight #>      0-25K     25-35K     35-50K     50-75K    75-100K   100-150K      150K+  #> 0.17353726 0.09405487 0.14064324 0.18922885 0.15252025 0.16103245 0.08898309  #>  #> $race_weight #>                 White              Hispanic Not white or Hispanic  #>            0.73559778            0.17719770            0.08720452  #>  sapply(wtvars, function(x) weights::wpct(svy[[x]])) #> $age_weight #>     18-34     35-54       55+  #> 0.2766497 0.2944162 0.4289340  #>  #> $income_weight #>      0-25K     25-35K     35-50K     50-75K    75-100K   100-150K      150K+  #> 0.15071973 0.12785775 0.14309907 0.20491109 0.15071973 0.15410669 0.06858594  #>  #> $race_weight #>                 White              Hispanic Not white or Hispanic  #>            0.82387807            0.09652837            0.07959356  #>   # run weighting svy_wts <- rake_weight(svy, pop_target, \"Vrid\") #> Warning: Targets for age_weight do not sum to 100%. Adjusting values to total 100% #> [1] \"Raking converged in 18 iterations\" svy <- svy_wts$svy sapply(wtvars, function(x) weights::wpct(svy[[x]], svy$weight)) #> $age_weight #>     18-34     35-54       55+  #> 0.3514503 0.3486601 0.2998896  #>  #> $income_weight #>      0-25K     25-35K     35-50K     50-75K    75-100K   100-150K      150K+  #> 0.17353726 0.09405487 0.14064324 0.18922885 0.15252025 0.16103245 0.08898309  #>  #> $race_weight #>                 White              Hispanic Not white or Hispanic  #>            0.73559778            0.17719770            0.08720452  #>  summary(svy_wts$wts) #> $convergence #> [1] \"Complete convergence was achieved after 18 iterations\" #>  #> $base.weights #> [1] \"No Base Weights Were Used\" #>  #> $raking.variables #> [1] \"age_weight\"    \"income_weight\" \"race_weight\"   #>  #> $weight.summary #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>   0.441   0.721   1.000   1.000   1.161   2.227  #>  #> $selection.method #> [1] \"variable selection conducted using _pctlim_ - discrepancies selected using _total_.\" #>  #> $general.design.effect #> [1] 1.146602 #>  #> $age_weight #>          Target Unweighted N Unweighted %     Wtd N     Wtd % Change in % #> 18-34 0.3514503          327    0.2766497  415.4143 0.3514503  0.07480056 #> 35-54 0.3486601          348    0.2944162  412.1162 0.3486601  0.05424384 #> 55+   0.2998896          507    0.4289340  354.4695 0.2998896 -0.12904440 #> Total 1.0000000         1182    1.0000000 1182.0000 1.0000000  0.25808881 #>        Resid. Disc. Orig. Disc. #> 18-34  1.110223e-16  0.07480056 #> 35-54  2.220446e-16  0.05424384 #> 55+   -3.330669e-16 -0.12904440 #> Total  6.661338e-16  0.25808881 #>  #> $income_weight #>              Target Unweighted N Unweighted %     Wtd N      Wtd %  Change in % #> 0-25K    0.17353726          178   0.15071973  204.9944 0.17353726  0.022817533 #> 25-35K   0.09405487          151   0.12785775  111.1042 0.09405487 -0.033802878 #> 35-50K   0.14064324          169   0.14309907  166.1377 0.14064324 -0.002455831 #> 50-75K   0.18922885          242   0.20491109  223.5304 0.18922885 -0.015682244 #> 75-100K  0.15252025          178   0.15071973  180.1676 0.15252025  0.001800522 #> 100-150K 0.16103245          182   0.15410669  190.2228 0.16103245  0.006925756 #> 150K+    0.08898309           81   0.06858594  105.1131 0.08898309  0.020397142 #> Total    1.00000000         1181   1.00000000 1181.2703 1.00000000  0.103881906 #>           Resid. Disc.  Orig. Disc. #> 0-25K     1.387779e-16  0.022817533 #> 25-35K    0.000000e+00 -0.033802878 #> 35-50K   -2.775558e-17 -0.002455831 #> 50-75K   -6.661338e-16 -0.015682244 #> 75-100K   6.383782e-16  0.001800522 #> 100-150K  2.775558e-17  0.006925756 #> 150K+     1.249001e-16  0.020397142 #> Total     1.623701e-15  0.103881906 #>  #> $race_weight #>                           Target Unweighted N Unweighted %     Wtd N      Wtd % #> White                 0.73559778          973   0.82387807  868.9398 0.73559778 #> Hispanic              0.17719770          114   0.09652837  209.3184 0.17719770 #> Not white or Hispanic 0.08720452           94   0.07959356  103.0121 0.08720452 #> Total                 1.00000000         1181   1.00000000 1181.2703 1.00000000 #>                        Change in %  Resid. Disc.  Orig. Disc. #> White                 -0.088280289  4.440892e-16 -0.088280289 #> Hispanic               0.080669338 -3.885781e-16  0.080669338 #> Not white or Hispanic  0.007610952 -2.775558e-17  0.007610952 #> Total                  0.176560579  8.604228e-16  0.176560579 #>"},{"path":"/reference/svy.html","id":null,"dir":"Reference","previous_headings":"","what":"Survey sample data — svy","title":"Survey sample data — svy","text":"Survey sample data","code":""},{"path":"/reference/svy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Survey sample data — svy","text":"","code":"svy"},{"path":"/reference/svy.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Survey sample data — svy","text":"list containing 2 data frames person person-level demographic variables act person-activity-level activity data","code":""},{"path":[]}]
